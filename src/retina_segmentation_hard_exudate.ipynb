{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34202942",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy\n",
    "#!pip install matplotlib\n",
    "#!pip install monai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, DataLoader, decollate_batch\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    ScaleIntensityd,\n",
    "    RandRotate90d,\n",
    "    RandFlipd,\n",
    "    RandGaussianNoised,  # Fix typo here\n",
    "    LambdaD,  \n",
    "    RandAdjustContrastd,\n",
    "    RandZoomd,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"GPU is available\")\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"GPU is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349e9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_config()\n",
    "set_determinism(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c6429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup data directory and file lists\n",
    "# /home/hamada/retina_segmentation/microaneurysm/images_microaneurysm\n",
    "data_dir = \"/home/hamada/retina_segmentation/hard_exudate\"\n",
    "train_image_dir = os.path.join(data_dir, \"images_hard_exudate\")\n",
    "train_mask_dir = os.path.join(data_dir, \"masks_hard_exudate\")\n",
    "\n",
    "# Original full dataset\n",
    "all_images = sorted(glob.glob(os.path.join(train_image_dir, \"*.jpg\")))\n",
    "all_masks = sorted(glob.glob(os.path.join(train_mask_dir, \"*.png\")))\n",
    "\n",
    "# Verify correspondence\n",
    "assert len(all_images) == len(all_masks), \"Image-mask count mismatch!\"\n",
    "for img, msk in zip(all_images, all_masks):\n",
    "    assert os.path.basename(img).split(\".\")[0] == os.path.basename(msk).split(\".\")[0], \"Mismatched filenames!\"\n",
    "\n",
    "# Split indices\n",
    "total = len(all_images)\n",
    "train_count = int(0.8 * total)\n",
    "val_count = int(0.1 * total)\n",
    "test_count = total - train_count - val_count\n",
    "\n",
    "# Create splits\n",
    "train_files = [{\"image\": all_images[i], \"mask\": all_masks[i]} for i in range(train_count)]\n",
    "val_files = [{\"image\": all_images[i+train_count], \"mask\": all_masks[i+train_count]} for i in range(val_count)]\n",
    "test_files = [{\"image\": all_images[i+train_count+val_count], \"mask\": all_masks[i+train_count+val_count]} for i in range(test_count)]\n",
    "\n",
    "print(f\"Total samples: {total}\")\n",
    "print(f\"Training: {len(train_files)}, Validation: {len(val_files)}, Testing: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeda39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_rgb_overlay(sample):\n",
    "    image = np.moveaxis(sample[\"image\"].numpy(), 0, -1)  # CHW â†’ HWC\n",
    "    mask = sample[\"mask\"].numpy().squeeze()\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"RGB Image\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.title(\"Mask\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(image)\n",
    "    plt.imshow(mask, alpha=0.5, cmap=\"jet\")\n",
    "    plt.title(\"Overlay\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a97c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transforms\n",
    "\n",
    "train_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0),\n",
    "    LambdaD(keys=[\"mask\"], func=lambda x: (x > 200).astype(np.float32)),\n",
    "    \n",
    "    # Enhanced augmentations\n",
    "    RandRotate90d(keys=[\"image\", \"mask\"], prob=0.75),  # Higher probability\n",
    "    RandFlipd(keys=[\"image\", \"mask\"], prob=0.5),\n",
    "    RandGaussianNoised(keys=[\"image\"], prob=0.5, std=0.05),\n",
    "    RandAdjustContrastd(keys=[\"image\"], prob=0.5, gamma=(0.8, 1.2)),\n",
    "    RandZoomd(keys=[\"image\", \"mask\"], prob=0.5, min_zoom=0.8, max_zoom=1.2),\n",
    "    \n",
    "    ToTensord(keys=[\"image\", \"mask\"]),\n",
    "])\n",
    "\n",
    "# Validation transforms (no random augmentations)\n",
    "val_transforms = Compose([\n",
    "    LoadImaged(keys=[\"image\", \"mask\"]),\n",
    "    EnsureChannelFirstd(keys=[\"image\", \"mask\"]),\n",
    "    ScaleIntensityd(keys=[\"image\"], minv=0.0, maxv=1.0),\n",
    "    LambdaD(keys=[\"mask\"], func=lambda x: (x > 200).astype(np.float32)),\n",
    "    ToTensord(keys=[\"image\", \"mask\"]),\n",
    "])\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=0.5)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=0.5)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "# Check mask validity\n",
    "sample = train_ds[0]\n",
    "print(\"Unique mask values:\", np.unique(sample[\"mask\"].numpy()))\n",
    "# Should output [0., 1.] - if not, mask processing is broken\n",
    "\n",
    "\n",
    "# Visualize sample training data\n",
    "show_rgb_overlay(train_ds[0])\n",
    "\n",
    "# Create model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Deeper UNet with residual blocks\n",
    "model = UNet(\n",
    "    spatial_dims=2,\n",
    "    in_channels=3,\n",
    "    out_channels=2,\n",
    "    channels=(32, 64, 128, 256, 512),  # Increased capacity\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=4,  # More residual blocks\n",
    "    norm=\"BATCH\",  # Add batch normalization\n",
    ").to(device)\n",
    "\n",
    "loss_func = DiceCELoss(\n",
    "    softmax=True,\n",
    "    to_onehot_y=True,\n",
    "    weight=torch.tensor([1.0, 15.0]).to(device)  # Class weights for CE term\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "\n",
    "\n",
    "# Training loop\n",
    "max_epochs = 50\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "\n",
    "# Implement learning rate warmup\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    total_steps=len(train_loader)*max_epochs,\n",
    "    pct_start=0.3\n",
    ")\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # Training\n",
    "    for batch_data in train_loader:\n",
    "        inputs = batch_data[\"image\"].to(device)\n",
    "        masks = batch_data[\"mask\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, masks)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= len(train_loader)\n",
    "    print(f\"Train loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        metric_sum = 0.0\n",
    "        \n",
    "        for val_data in val_loader:\n",
    "            val_images = val_data[\"image\"].to(device)\n",
    "            val_masks = val_data[\"mask\"].to(device)\n",
    "            \n",
    "            val_outputs = model(val_images)\n",
    "            val_probs = torch.softmax(val_outputs, dim=1)\n",
    "            \n",
    "            dice_metric(y_pred=val_probs, y=val_masks)\n",
    "        \n",
    "        metric = dice_metric.aggregate().item()\n",
    "        dice_metric.reset()\n",
    "        \n",
    "        if metric > best_metric:\n",
    "            best_metric = metric\n",
    "            best_metric_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        \n",
    "        print(f\"Validation Dice: {metric:.4f}\")\n",
    "\n",
    "        # Add this inside validation loop\n",
    "        if epoch % 2 == 0:  # Every 2 epochs\n",
    "            with torch.no_grad():\n",
    "                # Randomly select 3 samples from validation set\n",
    "                vis_indices = np.random.choice(len(val_ds), 3, replace=False)\n",
    "                \n",
    "                plt.figure(figsize=(15, 5))\n",
    "                for i, idx in enumerate(vis_indices):\n",
    "                    sample = val_ds[idx]\n",
    "                    image = sample[\"image\"].unsqueeze(0).to(device)\n",
    "                    mask = sample[\"mask\"].squeeze().cpu().numpy()\n",
    "                    \n",
    "                    # Get prediction\n",
    "                    pred = model(image)\n",
    "                    pred_mask = torch.argmax(pred, dim=1).squeeze().cpu().numpy()\n",
    "                    \n",
    "                    # Convert image for display\n",
    "                    img_display = image[0].cpu().numpy().transpose(1, 2, 0)  # (H, W, C)\n",
    "                    \n",
    "                    # Plot\n",
    "                    plt.subplot(3, 3, i*3+1)\n",
    "                    plt.imshow(img_display)\n",
    "                    plt.title(f\"Image {idx}\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(3, 3, i*3+2)\n",
    "                    plt.imshow(img_display)\n",
    "                    plt.imshow(mask, alpha=0.4, cmap=\"jet\")\n",
    "                    plt.title(\"Ground Truth\")\n",
    "                    plt.axis('off')\n",
    "                    \n",
    "                    plt.subplot(3, 3, i*3+3)\n",
    "                    plt.imshow(img_display)\n",
    "                    plt.imshow(pred_mask, alpha=0.4, cmap=\"jet\")\n",
    "                    plt.title(\"Prediction\")\n",
    "                    plt.axis('off')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "print(f\"Best validation Dice: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "\n",
    "# Testing visualization using the test split\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "test_ds = CacheDataset(data=test_files, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_image = test_data[\"image\"].to(device)\n",
    "        test_mask = test_data[\"mask\"].cpu().numpy().squeeze()\n",
    "        \n",
    "        test_output = model(test_image)\n",
    "        test_pred = torch.argmax(test_output, dim=1).squeeze().cpu().numpy()\n",
    "        \n",
    "        # Plot results\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Original Image (convert from tensor to HWC for RGB)\n",
    "        img_np = test_image[0].cpu().numpy().transpose(1, 2, 0)\n",
    "        \n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(\"Input Image\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(img_np)\n",
    "        plt.imshow(test_mask, alpha=0.5, cmap=\"jet\")\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(img_np)\n",
    "        plt.imshow(test_pred, alpha=0.5, cmap=\"jet\")\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "florance2_sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
